{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Features.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ucw603ef7hs",
        "outputId": "725e850d-9148-43ee-99f9-11d23dea40e3"
      },
      "source": [
        "# %pwd   (block comment/uncomment ctrl + /)\n",
        "# %ls\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiWdUeE0gSVc",
        "outputId": "58547406-0fa8-4269-aec6-ecb415e63e14"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/research   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpLrUUZGhUlb",
        "outputId": "80b686bf-f437-4f73-eead-e55be33fda38"
      },
      "source": [
        "%cd HERC/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/research/HERC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37Q527iOdq73"
      },
      "source": [
        "#pd.reset_option('^display.', silent=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoBfz9mr7yHP"
      },
      "source": [
        "#read file\n",
        "import pandas as pd   # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "rawData = pd.read_csv('texts.txt', header=None, sep=\"\\n\", names=['userTweets']) #separator is \\n # do not use index_col=0\n",
        "#rawData #rawData.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A29knHpHvcA7"
      },
      "source": [
        "rawData = rawData.dropna()\n",
        "#rawData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-O4Jwk8lrNf"
      },
      "source": [
        "# rawData['userID'] = rawData.index "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22Jfc0yeMgDL",
        "outputId": "f745a066-6586-49b6-b68d-5220a5e4bb3b"
      },
      "source": [
        "labels = pd.read_csv('score.txt', header=None, sep=\"\\n\", names=['userLabel']) \n",
        "labels\n",
        "labels['userLabel'].value_counts()  # check distribution of userLabel column\n",
        "import numpy as np # linear algebra \n",
        "labels['userLabel'].value_counts() / np.float(len(labels))  # view the percentage distribution of userLabel column"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.5\n",
              "0    0.5\n",
              "Name: userLabel, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYbFUvPo7cqS"
      },
      "source": [
        "We can see that percentage of observations of the class label 0 and 1 is 50% and 50%. So, class is balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSs8Bxl3NHr7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e0f0db57-4428-4662-aecb-a63f086d7030"
      },
      "source": [
        "rawData.merge(labels, on= rawData.index, how='left')  # rawData = rawData.join(labels) has restriction; # rawData = rawData[['userLabel','userTweets'] \n",
        "rawData\n",
        "#rawData.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userTweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it was fun while it but but i gotta gtf home😂 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT #USER#: George Floyd family to get $27milli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT #USER#: Russ's Moon Ball is one of the pret...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Romanian graftbuster’s firing violated rights,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Switzerland referendum: Voters support ban on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>I have 63 new followers from USA 🇺🇸, Italy 🇮🇹,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>RT #USER#: This squashed nug has us absolutely...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>I don't know about this one #URL# So #USER# sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>RT #USER#: I need a fuck it day. •Definition: ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>#USER# #USER# #USER# #USER# #USER# But these w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            userTweets\n",
              "0    it was fun while it but but i gotta gtf home😂 ...\n",
              "1    RT #USER#: George Floyd family to get $27milli...\n",
              "2    RT #USER#: Russ's Moon Ball is one of the pret...\n",
              "3    Romanian graftbuster’s firing violated rights,...\n",
              "4    Switzerland referendum: Voters support ban on ...\n",
              "..                                                 ...\n",
              "195  I have 63 new followers from USA 🇺🇸, Italy 🇮🇹,...\n",
              "196  RT #USER#: This squashed nug has us absolutely...\n",
              "197  I don't know about this one #URL# So #USER# sa...\n",
              "198  RT #USER#: I need a fuck it day. •Definition: ...\n",
              "199  #USER# #USER# #USER# #USER# #USER# But these w...\n",
              "\n",
              "[200 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCjxTdsBkOLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87298595-8c8f-457e-a0fa-0f37ed007e24"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf6FY4guxfWi",
        "outputId": "36eadca3-c93f-4ffc-e520-9bb5e1b108b3"
      },
      "source": [
        "test = \"123 45 6 7 !!! ! @ home😂 😂 😂😂😂 CAPTOL BOOK Dshook BOOK\"\n",
        "corpus = pd.DataFrame([test],  columns=['Document'])\n",
        "corpus['Document']=corpus['Document'].str.replace('[1-9]','',regex=True)\n",
        "corpus\n",
        "corpus['Document'].apply(word_tokenize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [!, !, !, !, @, home😂, 😂, 😂😂😂, CAPTOL, BOOK, D...\n",
              "Name: Document, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiEFoLG6BL95",
        "outputId": "379ae284-062c-464c-e3dd-d72c8fa0aa82"
      },
      "source": [
        "pip install pyspellchecker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.7/dist-packages (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYc-DyMRB5mL"
      },
      "source": [
        "from spellchecker import SpellChecker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RxgPIp4sCBqb",
        "outputId": "8c0cf0a9-6af9-499b-eca3-1fcafafdb639"
      },
      "source": [
        "spell.correction(\"book\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'book'"
            ]
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1rLkOcAIIld",
        "outputId": "74506004-4849-4d46-9101-922808cc2807"
      },
      "source": [
        "from nltk.corpus import words\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtH0c1hKINMy",
        "outputId": "74877a71-99b6-4f7b-8f1b-6e99c975b07d"
      },
      "source": [
        "\"fine\" in words.words()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h067kf2SiZe-",
        "outputId": "cd7fc8b3-c079-46d8-9d67-96e59c56822a"
      },
      "source": [
        "from nltk.corpus import words\n",
        "import time\n",
        "# Test Text\n",
        "text = \"she sell sea shell by the seashore\"\n",
        "\n",
        "# Original Method\n",
        "start = time.time()\n",
        "x = all([w in words.words() for w in \"she sell sea shell by the seashore\".split()])\n",
        "print(\"Duration Original Method: \", time.time() - start)\n",
        "\n",
        "# Time to convert words to set\n",
        "start = time.time()\n",
        "set_words = set(words.words())\n",
        "print(\"Time to generate set: \", time.time() - start)\n",
        "\n",
        "# Test Using Set (Singe iteration)\n",
        "start = time.time()\n",
        "x = all([w in set_words for w in \"she sell sea shell by the seashore\".split()])\n",
        "print(\"Set using 1 iteration: \", time.time() - start)\n",
        "\n",
        "# Test Using Set (10, 000 iterations)\n",
        "start = time.time()\n",
        "for k in range(100000):\n",
        "    x = all([w in set_words for w in \"she sell sea shell by the seashore\".split()])\n",
        "print(\"Set using 100, 000 iterations: \", time.time() - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration Original Method:  0.6524157524108887\n",
            "Time to generate set:  0.11699509620666504\n",
            "Set using 1 iteration:  0.0001609325408935547\n",
            "Set using 100, 000 iterations:  0.16324424743652344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjLderk6jNI3"
      },
      "source": [
        "set_words = set(words.words())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDdms6D6kn5V",
        "outputId": "62c62ede-5af9-4f38-f17c-49582ee0437f"
      },
      "source": [
        "isAllCapitalized(\"!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBzjMSKZzdse"
      },
      "source": [
        "rawData['userTweets']=rawData['userTweets'].str.replace('[1-9-$£+=]','',regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "uSqwNyt6f3Nm",
        "outputId": "9fdb7c66-5ad1-4902-9f50-e40203d4d08d"
      },
      "source": [
        "rawData['userTokens'] = rawData['userTweets'].apply(word_tokenize)\n",
        "rawData"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userTweets</th>\n",
              "      <th>userTokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it was fun while it but but i gotta gtf home😂 ...</td>\n",
              "      <td>[it, was, fun, while, it, but, but, i, got, ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT #USER#: George Floyd family to get million ...</td>\n",
              "      <td>[RT, #, USER, #, :, George, Floyd, family, to,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT #USER#: Russ's Moon Ball is one of the pret...</td>\n",
              "      <td>[RT, #, USER, #, :, Russ, 's, Moon, Ball, is, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Romanian graftbuster’s firing violated rights,...</td>\n",
              "      <td>[Romanian, graftbuster, ’, s, firing, violated...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Switzerland referendum: Voters support ban on ...</td>\n",
              "      <td>[Switzerland, referendum, :, Voters, support, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>I have  new followers from USA 🇺🇸, Italy 🇮🇹, U...</td>\n",
              "      <td>[I, have, new, followers, from, USA, 🇺🇸, ,, It...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>RT #USER#: This squashed nug has us absolutely...</td>\n",
              "      <td>[RT, #, USER, #, :, This, squashed, nug, has, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>I don't know about this one #URL# So #USER# sa...</td>\n",
              "      <td>[I, do, n't, know, about, this, one, #, URL, #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>RT #USER#: I need a fuck it day. •Definition: ...</td>\n",
              "      <td>[RT, #, USER, #, :, I, need, a, fuck, it, day,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>#USER# #USER# #USER# #USER# #USER# But these w...</td>\n",
              "      <td>[#, USER, #, #, USER, #, #, USER, #, #, USER, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            userTweets                                         userTokens\n",
              "0    it was fun while it but but i gotta gtf home😂 ...  [it, was, fun, while, it, but, but, i, got, ta...\n",
              "1    RT #USER#: George Floyd family to get million ...  [RT, #, USER, #, :, George, Floyd, family, to,...\n",
              "2    RT #USER#: Russ's Moon Ball is one of the pret...  [RT, #, USER, #, :, Russ, 's, Moon, Ball, is, ...\n",
              "3    Romanian graftbuster’s firing violated rights,...  [Romanian, graftbuster, ’, s, firing, violated...\n",
              "4    Switzerland referendum: Voters support ban on ...  [Switzerland, referendum, :, Voters, support, ...\n",
              "..                                                 ...                                                ...\n",
              "195  I have  new followers from USA 🇺🇸, Italy 🇮🇹, U...  [I, have, new, followers, from, USA, 🇺🇸, ,, It...\n",
              "196  RT #USER#: This squashed nug has us absolutely...  [RT, #, USER, #, :, This, squashed, nug, has, ...\n",
              "197  I don't know about this one #URL# So #USER# sa...  [I, do, n't, know, about, this, one, #, URL, #...\n",
              "198  RT #USER#: I need a fuck it day. •Definition: ...  [RT, #, USER, #, :, I, need, a, fuck, it, day,...\n",
              "199  #USER# #USER# #USER# #USER# #USER# But these w...  [#, USER, #, #, USER, #, #, USER, #, #, USER, ...\n",
              "\n",
              "[200 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo9n2MpsxJOU"
      },
      "source": [
        "def filteredWords(tokens: list):   # filteredWords(tokens: list)\n",
        "  filiteredWords = (\"#\",\".\",\":\", \",\",\"'s\",\"’\",\"s\", \"n't\",\"t\",\"i’m\",\"m\",\"I’m\",\"I\",\"i\",\"A\",\"'d\",\"'ll\",\"'re\",\"'ve\")\n",
        "  return [t for t in tokens if not (t in filiteredWords)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "WSVE6NOHubkE",
        "outputId": "9a264059-5b70-4c9a-d6ce-06a455bb722f"
      },
      "source": [
        "rawData['filteredTokens'] = rawData['userTokens'].map(filteredWords)\n",
        "rawData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userTweets</th>\n",
              "      <th>userTokens</th>\n",
              "      <th>filteredTokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it was fun while it but but i gotta gtf home😂 ...</td>\n",
              "      <td>[it, was, fun, while, it, but, but, i, got, ta...</td>\n",
              "      <td>[it, was, fun, while, it, but, but, got, ta, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT #USER#: George Floyd family to get million ...</td>\n",
              "      <td>[RT, #, USER, #, :, George, Floyd, family, to,...</td>\n",
              "      <td>[RT, USER, George, Floyd, family, to, get, mil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT #USER#: Russ's Moon Ball is one of the pret...</td>\n",
              "      <td>[RT, #, USER, #, :, Russ, 's, Moon, Ball, is, ...</td>\n",
              "      <td>[RT, USER, Russ, Moon, Ball, is, one, of, the,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Romanian graftbuster’s firing violated rights,...</td>\n",
              "      <td>[Romanian, graftbuster, ’, s, firing, violated...</td>\n",
              "      <td>[Romanian, graftbuster, firing, violated, righ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Switzerland referendum: Voters support ban on ...</td>\n",
              "      <td>[Switzerland, referendum, :, Voters, support, ...</td>\n",
              "      <td>[Switzerland, referendum, Voters, support, ban...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          userTweets  ...                                     filteredTokens\n",
              "0  it was fun while it but but i gotta gtf home😂 ...  ...  [it, was, fun, while, it, but, but, got, ta, g...\n",
              "1  RT #USER#: George Floyd family to get million ...  ...  [RT, USER, George, Floyd, family, to, get, mil...\n",
              "2  RT #USER#: Russ's Moon Ball is one of the pret...  ...  [RT, USER, Russ, Moon, Ball, is, one, of, the,...\n",
              "3  Romanian graftbuster’s firing violated rights,...  ...  [Romanian, graftbuster, firing, violated, righ...\n",
              "4  Switzerland referendum: Voters support ban on ...  ...  [Switzerland, referendum, Voters, support, ban...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WP4jsM6_Vl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e41e339-7d56-4a5b-867d-473e52b7b155"
      },
      "source": [
        "pip install emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 92 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 122 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 153 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 163 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 170 kB 9.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=1ee56569e46fe9065103586653783213effe72fb55c1a221f59381f184ffac9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VRdJBfnBZ12"
      },
      "source": [
        "import emoji"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlqR5V9-Mqmh"
      },
      "source": [
        "def isSpecialChar(word):\n",
        "  specialChars = \"!@#$%^&*?_=+-*[]<>()/\\|{}~;:'``…”...“‘\"\n",
        "  if any(char in specialChars for char in word):\n",
        "      return True\n",
        "  else:\n",
        "      return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJLGh8eJwlWo"
      },
      "source": [
        "def isEmoji(word):\n",
        "  word = emoji.demojize(word)\n",
        "  count = word.count(':')\n",
        "  if (count%2==0 and count>=2):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsOvvZtRpCb2"
      },
      "source": [
        "def emoji_sequenceLength(word):\n",
        "  word = emoji.demojize(word)\n",
        "  count = word.count(':')\n",
        "  return count/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHEuSKz24llm"
      },
      "source": [
        "def isAllCapitalized(word):\n",
        "  return (not isSpecialChar(word)) and word == word.upper() and (not isEmoji(word)) and (not word.isdigit())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1VkrJPGmNUb",
        "outputId": "1e827ce5-2584-41af-a6a3-81b3b8d8f1ac"
      },
      "source": [
        "userStats = {}\n",
        "userID = 0\n",
        "totalNumOfWords=0\n",
        "totalNumOfRetweet=0\n",
        "totalNumOfMention=0\n",
        "totalNumOfTag=0\n",
        "totalNumOfURL=0\n",
        "totalNumOfAllCapitalized=0\n",
        "totalNumOfSpecialChar=0\n",
        "totalNumOfEmoji=0\n",
        "totalNumOfMisspelled =0\n",
        "for tokens in rawData['filteredTokens']: # rawData.iloc[0:1]['filteredTokens']\n",
        "  numOfWords=0\n",
        "  numOfRetweet=0\n",
        "  numOfMention=0\n",
        "  numOfTag=0\n",
        "  numOfURL=0\n",
        "  numOfAllCapitalized=0\n",
        "  numOfEmoji=0\n",
        "  numOfSpecialChar=0\n",
        "  numOfMisspelled=0\n",
        "  captilized_maxSequenceLength=0\n",
        "  captilized_sumSequenceLength=0\n",
        "  emoji_maxSequenceLength=0\n",
        "  emoji_sumSequenceLength=0\n",
        "  for token in tokens:\n",
        "    numOfWords+=1\n",
        "    if  token == 'RT': numOfRetweet+=1\n",
        "    elif token == 'USER': numOfMention+=1\n",
        "    elif token == 'HASHTAG': numOfTag+=1\n",
        "    elif token == 'URL': numOfURL=1\n",
        "    elif isAllCapitalized(token): \n",
        "      #print('Capitalization:', token)\n",
        "      numOfAllCapitalized+=1\n",
        "      sequenceLength = len(token)\n",
        "      captilized_sumSequenceLength += sequenceLength\n",
        "      if(sequenceLength > captilized_maxSequenceLength):\n",
        "        captilized_maxSequenceLength = sequenceLength\n",
        "    elif isSpecialChar(token): \n",
        "      #print('SpecialChar:', token)\n",
        "      numOfSpecialChar+=1\n",
        "    elif isEmoji(token): \n",
        "      #print('Emoji', token)\n",
        "      numOfEmoji+=1\n",
        "      sequenceLength = emoji_sequenceLength(token)\n",
        "      emoji_sumSequenceLength += sequenceLength\n",
        "      if(sequenceLength > emoji_maxSequenceLength):\n",
        "        emoji_maxSequenceLength = sequenceLength\n",
        "    elif token not in set_words:\n",
        "      numOfMisspelled+=1\n",
        "\n",
        "  if (numOfAllCapitalized != 0 ):\n",
        "    captilized_avgSequenceLength = captilized_sumSequenceLength / numOfAllCapitalized\n",
        "  else: \n",
        "    #print('No all capitalized words', tokens)\n",
        "    captilized_avgSequenceLength = 0\n",
        "  if (numOfEmoji != 0):\n",
        "    emoji_avgSequenceLength = emoji_sumSequenceLength / numOfEmoji\n",
        "  else: \n",
        "    #print('No emojis',tokens)\n",
        "    emoji_avgSequenceLength = 0\n",
        "  lst = [numOfWords, numOfRetweet, numOfMention, numOfTag, numOfURL, numOfAllCapitalized, numOfEmoji, numOfSpecialChar, numOfMisspelled,  # 0-8\n",
        "         captilized_maxSequenceLength, captilized_avgSequenceLength, emoji_maxSequenceLength,  emoji_avgSequenceLength]  # 9-12\n",
        "  userStats[userID] = lst\n",
        "  userID+=1\n",
        "  totalNumOfWords+=numOfWords\n",
        "  totalNumOfRetweet+=numOfRetweet\n",
        "  totalNumOfMention+=numOfMention\n",
        "  totalNumOfTag+=numOfTag\n",
        "  totalNumOfURL+=numOfURL\n",
        "  totalNumOfAllCapitalized+=numOfAllCapitalized\n",
        "  totalNumOfEmoji+=numOfEmoji\n",
        "  totalNumOfSpecialChar+=numOfSpecialChar\n",
        "  totalNumOfMisspelled+=numOfMisspelled\n",
        "len(userStats)\n",
        "print(userStats[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2230, 123, 141, 1, 1, 7, 109, 65, 330, 5, 3.142857142857143, 15.0, 1.9724770642201834]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk5p1LUy1xzq"
      },
      "source": [
        "userID = 0\n",
        "for tokens in rawData['filteredTokens']:\n",
        "  cap_maxSequenceLength=0\n",
        "  cap_sumSequenceLength=0\n",
        "  cap_avgSequenceLength=0\n",
        "  capSequences = []\n",
        "  rt_maxSequenceLength=0\n",
        "  rt_sumSequenceLength=0\n",
        "  rt_avgSequenceLength=0\n",
        "  rtSequences = []\n",
        "  mention_maxSequenceLength=0\n",
        "  mention_sumSequenceLength=0\n",
        "  mention_avgSequenceLength=0\n",
        "  mentionSequences = []\n",
        "  URL_maxSequenceLength=0\n",
        "  URL_sumSequenceLength=0\n",
        "  URL_avgSequenceLength=0\n",
        "  URLSequences = []\n",
        "  HASHTAG_maxSequenceLength=0\n",
        "  HASHTAG_sumSequenceLength=0\n",
        "  HASHTAG_avgSequenceLength=0\n",
        "  HASHTAGSequences = []\n",
        "  specialChar_maxSequenceLength=0\n",
        "  specialChar_sumSequenceLength=0\n",
        "  specialChar_avgSequenceLength=0\n",
        "  specialCharSequences = []\n",
        "  emoji_maxSequenceLength=0\n",
        "  emoji_sumSequenceLength=0\n",
        "  emoji_avgSequenceLength=0\n",
        "  emojiSequences = []\n",
        "  misspell_maxSequenceLength=0\n",
        "  misspell_sumSequenceLength=0\n",
        "  misspell_avgSequenceLength=0\n",
        "  misspellSequences = []\n",
        "  tokenIndex = 0 \n",
        "  while(tokenIndex < len(tokens)):\n",
        "    if tokens[tokenIndex]=='RT':\n",
        "      rtSequence = []\n",
        "      rtSequence.append(tokens[tokenIndex])\n",
        "      tokenIndex+=1\n",
        "      while(tokenIndex < len(tokens) and tokens[tokenIndex]=='RT'):\n",
        "        rtSequence.append(tokens[tokenIndex])\n",
        "        tokenIndex+=1\n",
        "      sequenceLength = len(rtSequence)\n",
        "      rt_sumSequenceLength += sequenceLength\n",
        "      if(sequenceLength > rt_maxSequenceLength):\n",
        "        rt_maxSequenceLength = sequenceLength\n",
        "      rtSequences.append(rtSequence)\n",
        "      continue\n",
        "    elif tokens[tokenIndex]=='USER':\n",
        "      mentionSequence = []\n",
        "      mentionSequence.append(tokens[tokenIndex])\n",
        "      tokenIndex+=1\n",
        "      while(tokenIndex < len(tokens) and tokens[tokenIndex]=='USER'):\n",
        "        mentionSequence.append(tokens[tokenIndex])\n",
        "        tokenIndex+=1\n",
        "      sequenceLength = len(mentionSequence)\n",
        "      mention_sumSequenceLength += sequenceLength\n",
        "      if(sequenceLength > mention_maxSequenceLength):\n",
        "        mention_maxSequenceLength = sequenceLength\n",
        "      mentionSequences.append(mentionSequence)\n",
        "      continue\n",
        "    elif tokens[tokenIndex]=='HASHTAG':\n",
        "      HASHTAGSequence = []\n",
        "      HASHTAGSequence.append(tokens[tokenIndex])\n",
        "      tokenIndex+=1\n",
        "      while(tokenIndex < len(tokens) and tokens[tokenIndex]=='HASHTAG'):\n",
        "        HASHTAGSequence.append(tokens[tokenIndex])\n",
        "        tokenIndex+=1\n",
        "      sequenceLength = len(HASHTAGSequence)\n",
        "      HASHTAG_sumSequenceLength += sequenceLength\n",
        "      if(sequenceLength > HASHTAG_maxSequenceLength):\n",
        "        HASHTAG_maxSequenceLength = sequenceLength\n",
        "      HASHTAGSequences.append(HASHTAGSequence)\n",
        "      continue\n",
        "    elif tokens[tokenIndex]=='URL':\n",
        "      URLSequence = []\n",
        "      URLSequence.append(tokens[tokenIndex])\n",
        "      tokenIndex+=1\n",
        "      while(tokenIndex < len(tokens) and tokens[tokenIndex]=='URL'):\n",
        "        URLSequence.append(tokens[tokenIndex])\n",
        "        tokenIndex+=1\n",
        "      sequenceLength = len(URLSequence)\n",
        "      URL_sumSequenceLength += sequenceLength\n",
        "      if(sequenceLength > URL_maxSequenceLength):\n",
        "        URL_maxSequenceLength = sequenceLength\n",
        "      URLSequences.append(URLSequence)\n",
        "      continue\n",
        "    elif isAllCapitalized(tokens[tokenIndex]): \n",
        "      capSequence = []\n",
        "      capSequence.append(tokens[tokenIndex])\n",
        "      tokenIndex+=1\n",
        "      while(tokenIndex < len(tokens) and isAllCapitalized(tokens[tokenIndex])):\n",
        "        capSequence.append(tokens[tokenIndex])\n",
        "        tokenIndex+=1\n",
        "      sequenceLength = len(capSequence)\n",
        "      cap_sumSequenceLength += sequenceLength\n",
        "      if(sequenceLength > cap_maxSequenceLength):\n",
        "        cap_maxSequenceLength = sequenceLength\n",
        "      capSequences.append(capSequence)\n",
        "      continue\n",
        "    elif isSpecialChar(tokens[tokenIndex]): \n",
        "      specialCharSequence = []\n",
        "      specialCharSequence.append(tokens[tokenIndex])\n",
        "      tokenIndex+=1\n",
        "      while(tokenIndex < len(tokens) and isSpecialChar(tokens[tokenIndex])):\n",
        "        specialCharSequence.append(tokens[tokenIndex])\n",
        "        tokenIndex+=1\n",
        "      sequenceLength = len(specialCharSequence)\n",
        "      specialChar_sumSequenceLength += sequenceLength\n",
        "      if(sequenceLength > specialChar_maxSequenceLength):\n",
        "        specialChar_maxSequenceLength = sequenceLength\n",
        "      specialCharSequences.append(specialCharSequence)\n",
        "      continue\n",
        "    elif isEmoji(tokens[tokenIndex]): \n",
        "      emojiSequence = []\n",
        "      emojiSequence.append(tokens[tokenIndex])\n",
        "      tokenIndex+=1\n",
        "      while(tokenIndex < len(tokens) and isEmoji(tokens[tokenIndex])):\n",
        "        emojiSequence.append(tokens[tokenIndex])\n",
        "        tokenIndex+=1\n",
        "      sequenceLength = len(emojiSequence)\n",
        "      emoji_sumSequenceLength += sequenceLength\n",
        "      if(sequenceLength > emoji_maxSequenceLength):\n",
        "        emoji_maxSequenceLength = sequenceLength\n",
        "      emojiSequences.append(emojiSequence)\n",
        "      continue\n",
        "    elif tokens[tokenIndex] not in set_words: \n",
        "      misspellSequence = []\n",
        "      misspellSequence.append(tokens[tokenIndex])\n",
        "      tokenIndex+=1\n",
        "      while(tokenIndex < len(tokens) and (tokens[tokenIndex] not in set_words)):\n",
        "        misspellSequence.append(tokens[tokenIndex])\n",
        "        tokenIndex+=1\n",
        "      sequenceLength = len(misspellSequence)\n",
        "      misspell_sumSequenceLength += sequenceLength\n",
        "      if(sequenceLength > misspell_maxSequenceLength):\n",
        "        misspell_maxSequenceLength = sequenceLength\n",
        "      misspellSequences.append(misspellSequence)\n",
        "      continue\n",
        "    tokenIndex+=1\n",
        "  if (len(capSequences) != 0):\n",
        "    cap_avgSequenceLength = cap_sumSequenceLength / len(capSequences)\n",
        "  if (len(emojiSequences) != 0):\n",
        "    emoji_avgSequenceLength = emoji_sumSequenceLength / len(emojiSequences)\n",
        "  if (len(specialCharSequences) != 0):\n",
        "    specialChar_avgSequenceLength = specialChar_sumSequenceLength / len(specialCharSequences)\n",
        "  if (len(HASHTAGSequences) != 0):\n",
        "    HASHTAG_avgSequenceLength = HASHTAG_sumSequenceLength / len(HASHTAGSequences)  \n",
        "  if (len(mentionSequences) != 0):\n",
        "    mention_avgSequenceLength = mention_sumSequenceLength / len(mentionSequences)  \n",
        "  if (len(URLSequences) != 0):\n",
        "    URL_avgSequenceLength = URL_sumSequenceLength / len(URLSequences)  \n",
        "  if (len(rtSequences) != 0):\n",
        "    rt_avgSequenceLength = rt_sumSequenceLength / len(rtSequences)  \n",
        "  if (len(misspellSequences) != 0):\n",
        "    misspell_avgSequenceLength = misspell_sumSequenceLength / len(misspellSequences)  \n",
        "  userStats[userID].append(cap_maxSequenceLength) #13\n",
        "  userStats[userID].append(cap_avgSequenceLength) #14\n",
        "  userStats[userID].append(emoji_maxSequenceLength) #15\n",
        "  userStats[userID].append(emoji_avgSequenceLength) #16\n",
        "  userStats[userID].append(specialChar_maxSequenceLength)   #17\n",
        "  userStats[userID].append(specialChar_avgSequenceLength)   #18\n",
        "  userStats[userID].append(HASHTAG_maxSequenceLength)   #19\n",
        "  userStats[userID].append(HASHTAG_avgSequenceLength)   #20  \n",
        "  userStats[userID].append(mention_maxSequenceLength)   #21\n",
        "  userStats[userID].append(mention_avgSequenceLength)   #22  \n",
        "  userStats[userID].append(URL_maxSequenceLength)   #23\n",
        "  userStats[userID].append(URL_avgSequenceLength)   #24  \n",
        "  userStats[userID].append(rt_maxSequenceLength)   #25\n",
        "  userStats[userID].append(rt_avgSequenceLength)   #26  \n",
        "  userStats[userID].append(misspell_maxSequenceLength)   #27\n",
        "  userStats[userID].append(misspell_avgSequenceLength)   #28  \n",
        "  userID+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjtssF99nPUL",
        "outputId": "d7c5d95d-9b73-4fd3-bee5-e6447fb608ac"
      },
      "source": [
        "for userID in range(5):\n",
        "  print(userID, userStats[userID])\n",
        "# userStats\n",
        "# lst = [numOfWords, numOfRetweet, numOfMention, numOfTag, numOfURL, numOfAllCapitalized, numOfEmoji, numOfSpecialChar, \n",
        "#          captilized_maxSequenceLength, captilized_avgSequenceLength, emoji_maxSequenceLength,  emoji_avgSequenceLength, \n",
        "#          specialChar_maxSequenceLength, specialChar_avgSequenceLength] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [2230, 123, 141, 1, 1, 7, 109, 65, 330, 5, 3.142857142857143, 15.0, 1.9724770642201834, 2, 1.25, 1, 1.0, 2, 1.0930232558139534, 1, 1.0, 4, 1.0515463917525774, 1, 1.0, 1, 1.0, 10, 1.815686274509804]\n",
            "1 [2438, 23, 144, 11, 1, 59, 8, 159, 471, 8, 3.4237288135593222, 3.0, 1.75, 6, 1.4594594594594594, 1, 1.0, 3, 1.183673469387755, 1, 1.0, 6, 1.3409090909090908, 2, 1.0602409638554218, 1, 1.0, 8, 1.7264705882352942]\n",
            "2 [1717, 31, 68, 5, 1, 18, 44, 76, 366, 8, 3.0, 4.0, 1.5681818181818181, 5, 1.4615384615384615, 1, 1.0, 3, 1.0869565217391304, 1, 1.0, 4, 1.1428571428571428, 1, 1.0, 1, 1.0, 10, 1.7098039215686274]\n",
            "3 [2508, 2, 58, 0, 1, 137, 0, 111, 822, 12, 3.678832116788321, 0, 0, 9, 1.3333333333333333, 0, 0, 2, 1.1320754716981132, 0, 0, 1, 1.0, 2, 1.0853658536585367, 0, 0, 19, 2.4597156398104265]\n",
            "4 [2679, 61, 93, 213, 1, 61, 4, 132, 654, 8, 3.278688524590164, 3.0, 2.0, 8, 1.8611111111111112, 1, 1.0, 3, 1.0963855421686748, 5, 1.6790123456790123, 2, 1.1914893617021276, 1, 1.0, 1, 1.0, 22, 2.296675191815857]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOIStCYWxF_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1971814-1696-4e39-b753-9d46b9fa0be9"
      },
      "source": [
        "targets = [] # variable targets store class outcomes\n",
        "for label in labels['userLabel']:\n",
        "  targets.append(label)\n",
        "print(targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fInnBCX9Qba-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f70eba1-8929-4a14-cbf6-67469cb20334"
      },
      "source": [
        "cap_features = []\n",
        "cap_inputs = []  # Variable inputs will store the features (feature vector) \n",
        "for user in userStats:\n",
        "  cap_prop = userStats[user][5] / userStats[user][0]\n",
        "  cap_max_char = userStats[user][9]\n",
        "  cap_avg_char = userStats[user] [10]\n",
        "  cap_max_token = userStats[user] [13]\n",
        "  cap_avg_token = userStats[user] [14]\n",
        "  cap_features = [cap_prop, cap_max_char, cap_avg_char,cap_max_token, cap_avg_token ]\n",
        "  cap_inputs.append(cap_features)\n",
        "print(cap_inputs[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.003139013452914798, 5, 3.142857142857143, 2, 1.25], [0.02420016406890894, 8, 3.4237288135593222, 6, 1.4594594594594594], [0.010483401281304601, 8, 3.0, 5, 1.4615384615384615], [0.054625199362041466, 12, 3.678832116788321, 9, 1.3333333333333333], [0.02276969018290407, 8, 3.278688524590164, 8, 1.8611111111111112]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlu_m3Byvqrt",
        "outputId": "4f4040de-e40e-439b-dca1-ec87f889bc18"
      },
      "source": [
        "emoji_features = []\n",
        "emoji_inputs = []   \n",
        "for user in userStats:\n",
        "  emoji_prop = userStats[user][6] / userStats[user][0]\n",
        "  emoji_max_char = userStats[user][11]\n",
        "  emoji_avg_char = userStats[user] [12]\n",
        "  emoji_max_token = userStats[user][15]\n",
        "  emoji_avg_token = userStats[user] [16]\n",
        "  emoji_features = [emoji_prop, emoji_max_char, emoji_avg_char, emoji_max_token, emoji_avg_token]\n",
        "  emoji_inputs.append(emoji_features)\n",
        "print(emoji_inputs[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.04887892376681614, 15.0, 1.9724770642201834, 1, 1.0], [0.003281378178835111, 3.0, 1.75, 1, 1.0], [0.0256260920209668, 4.0, 1.5681818181818181, 1, 1.0], [0.0, 0, 0, 0, 0], [0.0014930944382232176, 3.0, 2.0, 1, 1.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXJRLUo6m3_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddcb72da-f3dc-4c80-dc25-1140182f3650"
      },
      "source": [
        "specialChar_features = []\n",
        "specialChar_inputs = []  \n",
        "for user in userStats:\n",
        "  specialChar_prop = userStats[user][7] / userStats[user][0]\n",
        "  specialChar_max = userStats[user][17]\n",
        "  specialChar_avg = userStats[user] [18]\n",
        "  specialChar_features = [specialChar_prop, specialChar_max, specialChar_avg]\n",
        "  specialChar_inputs.append(specialChar_features)\n",
        "print(specialChar_inputs[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.02914798206278027, 2, 1.0930232558139534], [0.06521739130434782, 3, 1.183673469387755], [0.0442632498543972, 3, 1.0869565217391304], [0.04425837320574163, 2, 1.1320754716981132], [0.04927211646136618, 3, 1.0963855421686748]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSO9-Pw-1YKO",
        "outputId": "04778d64-81b2-4785-b6f1-33fcf2a8cc20"
      },
      "source": [
        "hashtag_features = []\n",
        "hashtag_inputs = []  \n",
        "for user in userStats:\n",
        "  hashtag_prop = userStats[user][3] / userStats[user][0]\n",
        "  hashtag_max = userStats[user][19]\n",
        "  hashtag_avg = userStats[user] [20]\n",
        "  hashtag_features = [hashtag_prop, hashtag_max, hashtag_avg]\n",
        "  hashtag_inputs.append(hashtag_features)\n",
        "print(hashtag_inputs[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0004484304932735426, 1, 1.0], [0.004511894995898278, 1, 1.0], [0.0029120559114735, 1, 1.0], [0.0, 0, 0], [0.07950727883538634, 5, 1.6790123456790123]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEzRNC6U2ELq",
        "outputId": "746b77bd-9a84-408f-ac16-b6fb3f30cb30"
      },
      "source": [
        "mention_features = []\n",
        "mention_inputs = []  \n",
        "for user in userStats:\n",
        "  mention_prop = userStats[user][2] / userStats[user][0]\n",
        "  mention_max = userStats[user][21]\n",
        "  mention_avg = userStats[user] [22]\n",
        "  mention_features = [mention_prop, mention_max, mention_avg]\n",
        "  mention_inputs.append(mention_features)\n",
        "print(mention_inputs[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.06322869955156951, 4, 1.0515463917525774], [0.05906480721903199, 6, 1.3409090909090908], [0.039603960396039604, 4, 1.1428571428571428], [0.023125996810207338, 1, 1.0], [0.03471444568868981, 2, 1.1914893617021276]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chAIqAtp2eNr",
        "outputId": "e8fbeba9-e12c-4d1d-8ef0-6bb580fb25c6"
      },
      "source": [
        "URL_features = []\n",
        "URL_inputs = []  \n",
        "for user in userStats:\n",
        "  URL_prop = userStats[user][4] / userStats[user][0]\n",
        "  URL_max = userStats[user][23]\n",
        "  URL_avg = userStats[user] [24]\n",
        "  URL_features = [URL_prop, URL_max, URL_avg]\n",
        "  URL_inputs.append(URL_features)\n",
        "print(URL_inputs[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0004484304932735426, 1, 1.0], [0.00041017227235438887, 2, 1.0602409638554218], [0.0005824111822947001, 1, 1.0], [0.00039872408293460925, 2, 1.0853658536585367], [0.0003732736095558044, 1, 1.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5f9qc2_-W9S",
        "outputId": "4dd25727-8cee-4d33-bb51-ada3f91f1830"
      },
      "source": [
        "rt_prop=0\n",
        "rt_max=0\n",
        "rt_avg=0\n",
        "rt_features = []\n",
        "rt_inputs = []  \n",
        "for user in userStats:\n",
        "  rt_prop = userStats[user][1] / userStats[user][0]\n",
        "  rt_max = userStats[user][25]\n",
        "  rt_avg = userStats[user] [26]\n",
        "  rt_features = [rt_prop, rt_max, rt_avg]\n",
        "  rt_inputs.append(rt_features)\n",
        "print(rt_inputs[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.05515695067264574, 1, 1.0], [0.009433962264150943, 1, 1.0], [0.0180547466511357, 1, 1.0], [0.0007974481658692185, 0, 0], [0.02276969018290407, 1, 1.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fijcgf0zeyBR",
        "outputId": "00ad7157-0139-463b-ccca-043246051a0e"
      },
      "source": [
        "misspell_features = []\n",
        "misspell_inputs = []  \n",
        "for user in userStats:\n",
        "  misspell_prop = userStats[user][8] / userStats[user][0]\n",
        "  misspell_max = userStats[user][27]\n",
        "  misspell_avg = userStats[user][28]\n",
        "  misspell_features = [misspell_prop, misspell_max, misspell_avg]\n",
        "  misspell_inputs.append(misspell_features)\n",
        "print(misspell_inputs[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14798206278026907, 10, 1.815686274509804], [0.19319114027891715, 8, 1.7264705882352942], [0.2131624927198602, 10, 1.7098039215686274], [0.3277511961722488, 19, 2.4597156398104265], [0.24412094064949608, 22, 2.296675191815857]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM8t_0xqx1Az",
        "outputId": "f526629b-7671-4a78-ec54-bd2faf22c818"
      },
      "source": [
        "%store cap_inputs\n",
        "%store emoji_inputs\n",
        "%store specialChar_inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored 'cap_inputs' (list)\n",
            "Stored 'emoji_inputs' (list)\n",
            "Stored 'specialChar_inputs' (list)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfWAjKlloH_U",
        "outputId": "0adf92f3-eb45-4f1f-c9ec-ca5a49fc13ec"
      },
      "source": [
        "all_inputs =[]\n",
        "cap_mention_inputs =[]\n",
        "cap_emoji_inputs =[]\n",
        "cap_specialChar_inputs =[]\n",
        "cap_hashtag_inputs =[]\n",
        "cap_URL_inputs =[]\n",
        "cap_rt_inputs=[]\n",
        "cap_misspell_inputs=[]\n",
        "emoji_mention_inputs =[]\n",
        "cap_mention_URL_inputs =[]\n",
        "for user in userStats:\n",
        "  cap_prop = userStats[user][5] / userStats[user][0]\n",
        "  cap_max_char = userStats[user][9]\n",
        "  cap_avg_char = userStats[user] [10]\n",
        "  cap_max_token = userStats[user] [13]\n",
        "  cap_avg_token = userStats[user] [14]\n",
        "  emoji_prop = userStats[user][6] / userStats[user][0]\n",
        "  emoji_max_char = userStats[user][11]\n",
        "  emoji_avg_char = userStats[user] [12]\n",
        "  emoji_max_token = userStats[user][15]\n",
        "  emoji_avg_token = userStats[user] [16]\n",
        "  specialChar_prop = userStats[user][7] / userStats[user][0]\n",
        "  specialChar_max = userStats[user][17]\n",
        "  specialChar_avg = userStats[user] [18]\n",
        "  hashtag_prop = userStats[user][3] / userStats[user][0]\n",
        "  hashtag_max = userStats[user][19]\n",
        "  hashtag_avg = userStats[user] [20]\n",
        "  mention_prop = userStats[user][2] / userStats[user][0]\n",
        "  mention_max = userStats[user][21]\n",
        "  mention_avg = userStats[user] [22]\n",
        "  URL_prop = userStats[user][4] / userStats[user][0]\n",
        "  URL_max = userStats[user][23]\n",
        "  URL_avg = userStats[user] [24]\n",
        "  rt_prop = userStats[user][1] / userStats[user][0]\n",
        "  rt_max = userStats[user][25]\n",
        "  rt_avg = userStats[user] [26]\n",
        "  misspell_prop = userStats[user][8] / userStats[user][0]\n",
        "  misspell_max = userStats[user][27]\n",
        "  misspell_avg = userStats[user][28]\n",
        "  all_features = [cap_prop, cap_max_char, cap_avg_char, cap_max_token,cap_avg_token, emoji_prop, emoji_max_char, emoji_avg_char, emoji_max_token, emoji_avg_token, \n",
        "                  specialChar_prop,specialChar_max, specialChar_avg,hashtag_prop, hashtag_max,hashtag_avg, mention_prop, mention_max, mention_avg, \n",
        "                  URL_prop,URL_max, URL_avg,rt_prop,rt_max,rt_avg,   misspell_prop, misspell_max, misspell_avg]\n",
        "  cap_mention_features = [cap_prop, cap_max_char, cap_avg_char, cap_max_token,cap_avg_token, mention_prop, mention_max, mention_avg]\n",
        "  cap_emoji_features = [cap_prop, cap_max_char, cap_avg_char, cap_max_token,cap_avg_token, emoji_prop, emoji_max_char, emoji_avg_char, emoji_max_token, emoji_avg_token]\n",
        "  cap_specialChar_features = [cap_prop, cap_max_char, cap_avg_char, cap_max_token,cap_avg_token,specialChar_prop,specialChar_max, specialChar_avg ]\n",
        "  cap_hashtag_features = [cap_prop, cap_max_char, cap_avg_char, cap_max_token,cap_avg_token,hashtag_prop, hashtag_max,hashtag_avg]\n",
        "  cap_URL_features = [cap_prop, cap_max_char, cap_avg_char, cap_max_token,cap_avg_token,URL_prop,URL_max, URL_avg]\n",
        "  cap_rt_features = [cap_prop, cap_max_char, cap_avg_char, cap_max_token,cap_avg_token,rt_prop,rt_max,rt_avg]\n",
        "  cap_misspell_features= [cap_prop, cap_max_char, cap_avg_char, cap_max_token,cap_avg_token, misspell_prop, misspell_max, misspell_avg]\n",
        "  emoji_mention_features = [emoji_max_char, emoji_avg_char, emoji_max_token, emoji_avg_token,mention_prop, mention_max, mention_avg ]\n",
        "  cap_mention_URL_features = [cap_prop, cap_max_char, cap_avg_char, cap_max_token,cap_avg_token, mention_prop, mention_max, mention_avg, URL_prop,URL_max, URL_avg]\n",
        "  all_inputs.append(all_features)\n",
        "  cap_mention_inputs.append(cap_mention_features)  \n",
        "  cap_emoji_inputs.append(cap_emoji_features)   \n",
        "  cap_specialChar_inputs.append(cap_specialChar_features)  \n",
        "  cap_hashtag_inputs.append(cap_hashtag_features)   \n",
        "  cap_URL_inputs.append(cap_URL_features)   \n",
        "  cap_rt_inputs.append(cap_rt_features)\n",
        "  cap_misspell_inputs.append(cap_misspell_features)\n",
        "  emoji_mention_inputs.append(emoji_mention_features)\n",
        "  cap_mention_URL_inputs.append(cap_mention_URL_features)\n",
        "print(all_inputs[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.003139013452914798, 5, 3.142857142857143, 2, 1.25, 0.04887892376681614, 15.0, 1.9724770642201834, 1, 1.0, 0.02914798206278027, 2, 1.0930232558139534, 0.0004484304932735426, 1, 1.0, 0.06322869955156951, 4, 1.0515463917525774, 0.0004484304932735426, 1, 1.0, 0.05515695067264574, 1, 1.0, 0.14798206278026907, 10, 1.815686274509804], [0.02420016406890894, 8, 3.4237288135593222, 6, 1.4594594594594594, 0.003281378178835111, 3.0, 1.75, 1, 1.0, 0.06521739130434782, 3, 1.183673469387755, 0.004511894995898278, 1, 1.0, 0.05906480721903199, 6, 1.3409090909090908, 0.00041017227235438887, 2, 1.0602409638554218, 0.009433962264150943, 1, 1.0, 0.19319114027891715, 8, 1.7264705882352942], [0.010483401281304601, 8, 3.0, 5, 1.4615384615384615, 0.0256260920209668, 4.0, 1.5681818181818181, 1, 1.0, 0.0442632498543972, 3, 1.0869565217391304, 0.0029120559114735, 1, 1.0, 0.039603960396039604, 4, 1.1428571428571428, 0.0005824111822947001, 1, 1.0, 0.0180547466511357, 1, 1.0, 0.2131624927198602, 10, 1.7098039215686274], [0.054625199362041466, 12, 3.678832116788321, 9, 1.3333333333333333, 0.0, 0, 0, 0, 0, 0.04425837320574163, 2, 1.1320754716981132, 0.0, 0, 0, 0.023125996810207338, 1, 1.0, 0.00039872408293460925, 2, 1.0853658536585367, 0.0007974481658692185, 0, 0, 0.3277511961722488, 19, 2.4597156398104265], [0.02276969018290407, 8, 3.278688524590164, 8, 1.8611111111111112, 0.0014930944382232176, 3.0, 2.0, 1, 1.0, 0.04927211646136618, 3, 1.0963855421686748, 0.07950727883538634, 5, 1.6790123456790123, 0.03471444568868981, 2, 1.1914893617021276, 0.0003732736095558044, 1, 1.0, 0.02276969018290407, 1, 1.0, 0.24412094064949608, 22, 2.296675191815857]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZUV4YDt1IEg"
      },
      "source": [
        "# split X and y into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(cap_inputs, targets, test_size = 0.2, random_state = 0)  # 80% training and 20% test\n",
        "#X_train, X_test, y_train, y_test = train_test_split(emoji_inputs, targets, test_size = 0.2, random_state = 0)  # Accuracy: 0.5000\n",
        "#X_train, X_test, y_train, y_test = train_test_split(specialChar_inputs, targets, test_size = 0.2, random_state = 0) \n",
        "#X_train, X_test, y_train, y_test = train_test_split(hashtag_inputs, targets, test_size = 0.2, random_state = 0) \n",
        "#X_train, X_test, y_train, y_test = train_test_split(mention_inputs, targets, test_size = 0.2, random_state = 0)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(URL_inputs, targets, test_size = 0.2, random_state = 0)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(rt_inputs, targets, test_size = 0.2, random_state = 0)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(misspell_inputs, targets, test_size = 0.2, random_state = 0)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(all_inputs, targets, test_size = 0.2, random_state = 0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(emoji_mention_inputs, targets, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVaJPUHI9LU4"
      },
      "source": [
        " Run SVM and RandomForest with default hyperparameters \n",
        "\n",
        " Default hyperparameter means C=1.0, kernel=rbf and gamma=auto among other parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BAL-lrF39wk"
      },
      "source": [
        "#Import svm model\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "svc = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "#Train the model using the training sets\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "svc_pred = svc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23Gw5HGcsdEk"
      },
      "source": [
        "#from sklearn import model_selection\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# random forest model creation\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train,y_train)\n",
        "# predictions\n",
        "rfc_pred = rfc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUI5OJp34SVz",
        "outputId": "f57ba807-ee4c-448f-e99c-fa4aea3c07a3"
      },
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "\n",
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"SVC Accuracy: {0:0.4f}\".format(metrics.accuracy_score(y_test, svc_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY_u7t99x6rP",
        "outputId": "a39bf832-0cda-4ea4-8781-805445733227"
      },
      "source": [
        "# Model Accuracy: how often is the classifier correct?\n",
        "print(\"RFC Accuracy: {0:0.4f}\".format(metrics.accuracy_score(y_test, rfc_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6250\n"
          ]
        }
      ]
    }
  ]
}
